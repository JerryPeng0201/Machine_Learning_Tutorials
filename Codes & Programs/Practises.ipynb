{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Implement Linear Regression from scratch"
      ],
      "metadata": {
        "id": "POKz-3zWtzbY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J6i93twNtjWE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Data Generation\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Add a bias term (x0 = 1) to each sample\n",
        "X_b = np.c_[np.ones((100, 1)), X]\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_size = int(0.8 * len(X_b))\n",
        "X_train, X_test = X_b[:train_size], X_b[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# 2. Linear Regression with L2 Regularization\n",
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000, lambda_reg=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.lambda_reg = lambda_reg\n",
        "        self.theta = None\n",
        "\n",
        "    def compute_cost(self, X, y):\n",
        "        m = len(y)\n",
        "        # TODO: How to make a prediction? y = X*theta\n",
        "        predictions = None\n",
        "\n",
        "        # TODO: How to calculate the cost?\n",
        "        cost = None\n",
        "\n",
        "        # TODO: How to implement L2 regularizer?\n",
        "        reg_cost = None\n",
        "\n",
        "        return cost + reg_cost\n",
        "\n",
        "    def gradient_descent(self, X, y):\n",
        "        m = len(y)\n",
        "        self.theta = np.random.randn(X.shape[1], 1) # Randomly initialize a theta\n",
        "        for epoch in range(self.epochs):\n",
        "            # TODO: How to calculate the gradient?\n",
        "            gradients = None\n",
        "            gradients[1:] += (self.lambda_reg / m) * self.theta[1:]\n",
        "\n",
        "            # TODO: How to update theta?\n",
        "            self.theta = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X.dot(self.theta)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.gradient_descent(X_train, y_train)\n",
        "\n",
        "# 3. Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# TODO: Mean Squared Error\n",
        "mse = None\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "\n",
        "# TODO: R-squared score\n",
        "r2 = None\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "\n",
        "# Plotting the regression line\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, X_b.dot(model.theta), color='red')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression with L2 Regularization')\n",
        "plt.show()\n"
      ]
    }
  ]
}